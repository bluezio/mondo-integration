/**
 * Autogenerated by Thrift Compiler (0.9.3)
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 *  @generated
 */
package uk.ac.york.mondo.integration.api;

import org.apache.thrift.scheme.IScheme;
import org.apache.thrift.scheme.SchemeFactory;
import org.apache.thrift.scheme.StandardScheme;

import org.apache.thrift.scheme.TupleScheme;
import org.apache.thrift.protocol.TTupleProtocol;
import org.apache.thrift.protocol.TProtocolException;
import org.apache.thrift.EncodingUtils;
import org.apache.thrift.TException;
import org.apache.thrift.async.AsyncMethodCallback;
import org.apache.thrift.server.AbstractNonblockingServer.*;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.nio.ByteBuffer;
import java.util.Arrays;
import javax.annotation.Generated;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

@SuppressWarnings({"cast", "rawtypes", "serial", "unchecked"})
@Generated(value = "Autogenerated by Thrift Compiler (0.9.3)", date = "2016-01-27")
public class HawkQueryOptions implements org.apache.thrift.TBase<HawkQueryOptions, HawkQueryOptions._Fields>, java.io.Serializable, Cloneable, Comparable<HawkQueryOptions> {
  private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("HawkQueryOptions");

  private static final org.apache.thrift.protocol.TField REPOSITORY_PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField("repositoryPattern", org.apache.thrift.protocol.TType.STRING, (short)1);
  private static final org.apache.thrift.protocol.TField FILE_PATTERNS_FIELD_DESC = new org.apache.thrift.protocol.TField("filePatterns", org.apache.thrift.protocol.TType.LIST, (short)2);
  private static final org.apache.thrift.protocol.TField DEFAULT_NAMESPACES_FIELD_DESC = new org.apache.thrift.protocol.TField("defaultNamespaces", org.apache.thrift.protocol.TType.STRING, (short)3);
  private static final org.apache.thrift.protocol.TField INCLUDE_ATTRIBUTES_FIELD_DESC = new org.apache.thrift.protocol.TField("includeAttributes", org.apache.thrift.protocol.TType.BOOL, (short)4);
  private static final org.apache.thrift.protocol.TField INCLUDE_REFERENCES_FIELD_DESC = new org.apache.thrift.protocol.TField("includeReferences", org.apache.thrift.protocol.TType.BOOL, (short)5);
  private static final org.apache.thrift.protocol.TField INCLUDE_NODE_IDS_FIELD_DESC = new org.apache.thrift.protocol.TField("includeNodeIDs", org.apache.thrift.protocol.TType.BOOL, (short)6);
  private static final org.apache.thrift.protocol.TField INCLUDE_CONTAINED_FIELD_DESC = new org.apache.thrift.protocol.TField("includeContained", org.apache.thrift.protocol.TType.BOOL, (short)7);
  private static final org.apache.thrift.protocol.TField EFFECTIVE_METAMODELS_FIELD_DESC = new org.apache.thrift.protocol.TField("effectiveMetamodels", org.apache.thrift.protocol.TType.MAP, (short)8);

  private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
  static {
    schemes.put(StandardScheme.class, new HawkQueryOptionsStandardSchemeFactory());
    schemes.put(TupleScheme.class, new HawkQueryOptionsTupleSchemeFactory());
  }

  public String repositoryPattern; // optional
  public List<String> filePatterns; // optional
  public String defaultNamespaces; // optional
  public boolean includeAttributes; // optional
  public boolean includeReferences; // optional
  public boolean includeNodeIDs; // optional
  public boolean includeContained; // optional
  public Map<String,Map<String,List<String>>> effectiveMetamodels; // optional

  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
  public enum _Fields implements org.apache.thrift.TFieldIdEnum {
    REPOSITORY_PATTERN((short)1, "repositoryPattern"),
    FILE_PATTERNS((short)2, "filePatterns"),
    DEFAULT_NAMESPACES((short)3, "defaultNamespaces"),
    INCLUDE_ATTRIBUTES((short)4, "includeAttributes"),
    INCLUDE_REFERENCES((short)5, "includeReferences"),
    INCLUDE_NODE_IDS((short)6, "includeNodeIDs"),
    INCLUDE_CONTAINED((short)7, "includeContained"),
    EFFECTIVE_METAMODELS((short)8, "effectiveMetamodels");

    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

    static {
      for (_Fields field : EnumSet.allOf(_Fields.class)) {
        byName.put(field.getFieldName(), field);
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, or null if its not found.
     */
    public static _Fields findByThriftId(int fieldId) {
      switch(fieldId) {
        case 1: // REPOSITORY_PATTERN
          return REPOSITORY_PATTERN;
        case 2: // FILE_PATTERNS
          return FILE_PATTERNS;
        case 3: // DEFAULT_NAMESPACES
          return DEFAULT_NAMESPACES;
        case 4: // INCLUDE_ATTRIBUTES
          return INCLUDE_ATTRIBUTES;
        case 5: // INCLUDE_REFERENCES
          return INCLUDE_REFERENCES;
        case 6: // INCLUDE_NODE_IDS
          return INCLUDE_NODE_IDS;
        case 7: // INCLUDE_CONTAINED
          return INCLUDE_CONTAINED;
        case 8: // EFFECTIVE_METAMODELS
          return EFFECTIVE_METAMODELS;
        default:
          return null;
      }
    }

    /**
     * Find the _Fields constant that matches fieldId, throwing an exception
     * if it is not found.
     */
    public static _Fields findByThriftIdOrThrow(int fieldId) {
      _Fields fields = findByThriftId(fieldId);
      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
      return fields;
    }

    /**
     * Find the _Fields constant that matches name, or null if its not found.
     */
    public static _Fields findByName(String name) {
      return byName.get(name);
    }

    private final short _thriftId;
    private final String _fieldName;

    _Fields(short thriftId, String fieldName) {
      _thriftId = thriftId;
      _fieldName = fieldName;
    }

    public short getThriftFieldId() {
      return _thriftId;
    }

    public String getFieldName() {
      return _fieldName;
    }
  }

  // isset id assignments
  private static final int __INCLUDEATTRIBUTES_ISSET_ID = 0;
  private static final int __INCLUDEREFERENCES_ISSET_ID = 1;
  private static final int __INCLUDENODEIDS_ISSET_ID = 2;
  private static final int __INCLUDECONTAINED_ISSET_ID = 3;
  private byte __isset_bitfield = 0;
  private static final _Fields optionals[] = {_Fields.REPOSITORY_PATTERN,_Fields.FILE_PATTERNS,_Fields.DEFAULT_NAMESPACES,_Fields.INCLUDE_ATTRIBUTES,_Fields.INCLUDE_REFERENCES,_Fields.INCLUDE_NODE_IDS,_Fields.INCLUDE_CONTAINED,_Fields.EFFECTIVE_METAMODELS};
  public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
  static {
    Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
    tmpMap.put(_Fields.REPOSITORY_PATTERN, new org.apache.thrift.meta_data.FieldMetaData("repositoryPattern", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
    tmpMap.put(_Fields.FILE_PATTERNS, new org.apache.thrift.meta_data.FieldMetaData("filePatterns", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
            new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING))));
    tmpMap.put(_Fields.DEFAULT_NAMESPACES, new org.apache.thrift.meta_data.FieldMetaData("defaultNamespaces", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
    tmpMap.put(_Fields.INCLUDE_ATTRIBUTES, new org.apache.thrift.meta_data.FieldMetaData("includeAttributes", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
    tmpMap.put(_Fields.INCLUDE_REFERENCES, new org.apache.thrift.meta_data.FieldMetaData("includeReferences", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
    tmpMap.put(_Fields.INCLUDE_NODE_IDS, new org.apache.thrift.meta_data.FieldMetaData("includeNodeIDs", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
    tmpMap.put(_Fields.INCLUDE_CONTAINED, new org.apache.thrift.meta_data.FieldMetaData("includeContained", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.BOOL)));
    tmpMap.put(_Fields.EFFECTIVE_METAMODELS, new org.apache.thrift.meta_data.FieldMetaData("effectiveMetamodels", org.apache.thrift.TFieldRequirementType.OPTIONAL, 
        new org.apache.thrift.meta_data.MapMetaData(org.apache.thrift.protocol.TType.MAP, 
            new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING), 
            new org.apache.thrift.meta_data.MapMetaData(org.apache.thrift.protocol.TType.MAP, 
                new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING), 
            new org.apache.thrift.meta_data.ListMetaData(org.apache.thrift.protocol.TType.LIST, 
                    new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING))))));
    metaDataMap = Collections.unmodifiableMap(tmpMap);
    org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(HawkQueryOptions.class, metaDataMap);
  }

  public HawkQueryOptions() {
    this.repositoryPattern = "*";

    this.includeAttributes = true;

    this.includeReferences = true;

    this.includeNodeIDs = false;

    this.includeContained = true;

  }

  /**
   * Performs a deep copy on <i>other</i>.
   */
  public HawkQueryOptions(HawkQueryOptions other) {
    __isset_bitfield = other.__isset_bitfield;
    if (other.isSetRepositoryPattern()) {
      this.repositoryPattern = other.repositoryPattern;
    }
    if (other.isSetFilePatterns()) {
      List<String> __this__filePatterns = new ArrayList<String>(other.filePatterns);
      this.filePatterns = __this__filePatterns;
    }
    if (other.isSetDefaultNamespaces()) {
      this.defaultNamespaces = other.defaultNamespaces;
    }
    this.includeAttributes = other.includeAttributes;
    this.includeReferences = other.includeReferences;
    this.includeNodeIDs = other.includeNodeIDs;
    this.includeContained = other.includeContained;
    if (other.isSetEffectiveMetamodels()) {
      Map<String,Map<String,List<String>>> __this__effectiveMetamodels = new HashMap<String,Map<String,List<String>>>(other.effectiveMetamodels.size());
      for (Map.Entry<String, Map<String,List<String>>> other_element : other.effectiveMetamodels.entrySet()) {

        String other_element_key = other_element.getKey();
        Map<String,List<String>> other_element_value = other_element.getValue();

        String __this__effectiveMetamodels_copy_key = other_element_key;

        Map<String,List<String>> __this__effectiveMetamodels_copy_value = new HashMap<String,List<String>>(other_element_value.size());
        for (Map.Entry<String, List<String>> other_element_value_element : other_element_value.entrySet()) {

          String other_element_value_element_key = other_element_value_element.getKey();
          List<String> other_element_value_element_value = other_element_value_element.getValue();

          String __this__effectiveMetamodels_copy_value_copy_key = other_element_value_element_key;

          List<String> __this__effectiveMetamodels_copy_value_copy_value = new ArrayList<String>(other_element_value_element_value);

          __this__effectiveMetamodels_copy_value.put(__this__effectiveMetamodels_copy_value_copy_key, __this__effectiveMetamodels_copy_value_copy_value);
        }

        __this__effectiveMetamodels.put(__this__effectiveMetamodels_copy_key, __this__effectiveMetamodels_copy_value);
      }
      this.effectiveMetamodels = __this__effectiveMetamodels;
    }
  }

  public HawkQueryOptions deepCopy() {
    return new HawkQueryOptions(this);
  }

  @Override
  public void clear() {
    this.repositoryPattern = "*";

    this.filePatterns = null;
    this.defaultNamespaces = null;
    this.includeAttributes = true;

    this.includeReferences = true;

    this.includeNodeIDs = false;

    this.includeContained = true;

    this.effectiveMetamodels = null;
  }

  public String getRepositoryPattern() {
    return this.repositoryPattern;
  }

  public HawkQueryOptions setRepositoryPattern(String repositoryPattern) {
    this.repositoryPattern = repositoryPattern;
    return this;
  }

  public void unsetRepositoryPattern() {
    this.repositoryPattern = null;
  }

  /** Returns true if field repositoryPattern is set (has been assigned a value) and false otherwise */
  public boolean isSetRepositoryPattern() {
    return this.repositoryPattern != null;
  }

  public void setRepositoryPatternIsSet(boolean value) {
    if (!value) {
      this.repositoryPattern = null;
    }
  }

  public int getFilePatternsSize() {
    return (this.filePatterns == null) ? 0 : this.filePatterns.size();
  }

  public java.util.Iterator<String> getFilePatternsIterator() {
    return (this.filePatterns == null) ? null : this.filePatterns.iterator();
  }

  public void addToFilePatterns(String elem) {
    if (this.filePatterns == null) {
      this.filePatterns = new ArrayList<String>();
    }
    this.filePatterns.add(elem);
  }

  public List<String> getFilePatterns() {
    return this.filePatterns;
  }

  public HawkQueryOptions setFilePatterns(List<String> filePatterns) {
    this.filePatterns = filePatterns;
    return this;
  }

  public void unsetFilePatterns() {
    this.filePatterns = null;
  }

  /** Returns true if field filePatterns is set (has been assigned a value) and false otherwise */
  public boolean isSetFilePatterns() {
    return this.filePatterns != null;
  }

  public void setFilePatternsIsSet(boolean value) {
    if (!value) {
      this.filePatterns = null;
    }
  }

  public String getDefaultNamespaces() {
    return this.defaultNamespaces;
  }

  public HawkQueryOptions setDefaultNamespaces(String defaultNamespaces) {
    this.defaultNamespaces = defaultNamespaces;
    return this;
  }

  public void unsetDefaultNamespaces() {
    this.defaultNamespaces = null;
  }

  /** Returns true if field defaultNamespaces is set (has been assigned a value) and false otherwise */
  public boolean isSetDefaultNamespaces() {
    return this.defaultNamespaces != null;
  }

  public void setDefaultNamespacesIsSet(boolean value) {
    if (!value) {
      this.defaultNamespaces = null;
    }
  }

  public boolean isIncludeAttributes() {
    return this.includeAttributes;
  }

  public HawkQueryOptions setIncludeAttributes(boolean includeAttributes) {
    this.includeAttributes = includeAttributes;
    setIncludeAttributesIsSet(true);
    return this;
  }

  public void unsetIncludeAttributes() {
    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __INCLUDEATTRIBUTES_ISSET_ID);
  }

  /** Returns true if field includeAttributes is set (has been assigned a value) and false otherwise */
  public boolean isSetIncludeAttributes() {
    return EncodingUtils.testBit(__isset_bitfield, __INCLUDEATTRIBUTES_ISSET_ID);
  }

  public void setIncludeAttributesIsSet(boolean value) {
    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __INCLUDEATTRIBUTES_ISSET_ID, value);
  }

  public boolean isIncludeReferences() {
    return this.includeReferences;
  }

  public HawkQueryOptions setIncludeReferences(boolean includeReferences) {
    this.includeReferences = includeReferences;
    setIncludeReferencesIsSet(true);
    return this;
  }

  public void unsetIncludeReferences() {
    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __INCLUDEREFERENCES_ISSET_ID);
  }

  /** Returns true if field includeReferences is set (has been assigned a value) and false otherwise */
  public boolean isSetIncludeReferences() {
    return EncodingUtils.testBit(__isset_bitfield, __INCLUDEREFERENCES_ISSET_ID);
  }

  public void setIncludeReferencesIsSet(boolean value) {
    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __INCLUDEREFERENCES_ISSET_ID, value);
  }

  public boolean isIncludeNodeIDs() {
    return this.includeNodeIDs;
  }

  public HawkQueryOptions setIncludeNodeIDs(boolean includeNodeIDs) {
    this.includeNodeIDs = includeNodeIDs;
    setIncludeNodeIDsIsSet(true);
    return this;
  }

  public void unsetIncludeNodeIDs() {
    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __INCLUDENODEIDS_ISSET_ID);
  }

  /** Returns true if field includeNodeIDs is set (has been assigned a value) and false otherwise */
  public boolean isSetIncludeNodeIDs() {
    return EncodingUtils.testBit(__isset_bitfield, __INCLUDENODEIDS_ISSET_ID);
  }

  public void setIncludeNodeIDsIsSet(boolean value) {
    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __INCLUDENODEIDS_ISSET_ID, value);
  }

  public boolean isIncludeContained() {
    return this.includeContained;
  }

  public HawkQueryOptions setIncludeContained(boolean includeContained) {
    this.includeContained = includeContained;
    setIncludeContainedIsSet(true);
    return this;
  }

  public void unsetIncludeContained() {
    __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __INCLUDECONTAINED_ISSET_ID);
  }

  /** Returns true if field includeContained is set (has been assigned a value) and false otherwise */
  public boolean isSetIncludeContained() {
    return EncodingUtils.testBit(__isset_bitfield, __INCLUDECONTAINED_ISSET_ID);
  }

  public void setIncludeContainedIsSet(boolean value) {
    __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __INCLUDECONTAINED_ISSET_ID, value);
  }

  public int getEffectiveMetamodelsSize() {
    return (this.effectiveMetamodels == null) ? 0 : this.effectiveMetamodels.size();
  }

  public void putToEffectiveMetamodels(String key, Map<String,List<String>> val) {
    if (this.effectiveMetamodels == null) {
      this.effectiveMetamodels = new HashMap<String,Map<String,List<String>>>();
    }
    this.effectiveMetamodels.put(key, val);
  }

  public Map<String,Map<String,List<String>>> getEffectiveMetamodels() {
    return this.effectiveMetamodels;
  }

  public HawkQueryOptions setEffectiveMetamodels(Map<String,Map<String,List<String>>> effectiveMetamodels) {
    this.effectiveMetamodels = effectiveMetamodels;
    return this;
  }

  public void unsetEffectiveMetamodels() {
    this.effectiveMetamodels = null;
  }

  /** Returns true if field effectiveMetamodels is set (has been assigned a value) and false otherwise */
  public boolean isSetEffectiveMetamodels() {
    return this.effectiveMetamodels != null;
  }

  public void setEffectiveMetamodelsIsSet(boolean value) {
    if (!value) {
      this.effectiveMetamodels = null;
    }
  }

  public void setFieldValue(_Fields field, Object value) {
    switch (field) {
    case REPOSITORY_PATTERN:
      if (value == null) {
        unsetRepositoryPattern();
      } else {
        setRepositoryPattern((String)value);
      }
      break;

    case FILE_PATTERNS:
      if (value == null) {
        unsetFilePatterns();
      } else {
        setFilePatterns((List<String>)value);
      }
      break;

    case DEFAULT_NAMESPACES:
      if (value == null) {
        unsetDefaultNamespaces();
      } else {
        setDefaultNamespaces((String)value);
      }
      break;

    case INCLUDE_ATTRIBUTES:
      if (value == null) {
        unsetIncludeAttributes();
      } else {
        setIncludeAttributes((Boolean)value);
      }
      break;

    case INCLUDE_REFERENCES:
      if (value == null) {
        unsetIncludeReferences();
      } else {
        setIncludeReferences((Boolean)value);
      }
      break;

    case INCLUDE_NODE_IDS:
      if (value == null) {
        unsetIncludeNodeIDs();
      } else {
        setIncludeNodeIDs((Boolean)value);
      }
      break;

    case INCLUDE_CONTAINED:
      if (value == null) {
        unsetIncludeContained();
      } else {
        setIncludeContained((Boolean)value);
      }
      break;

    case EFFECTIVE_METAMODELS:
      if (value == null) {
        unsetEffectiveMetamodels();
      } else {
        setEffectiveMetamodels((Map<String,Map<String,List<String>>>)value);
      }
      break;

    }
  }

  public Object getFieldValue(_Fields field) {
    switch (field) {
    case REPOSITORY_PATTERN:
      return getRepositoryPattern();

    case FILE_PATTERNS:
      return getFilePatterns();

    case DEFAULT_NAMESPACES:
      return getDefaultNamespaces();

    case INCLUDE_ATTRIBUTES:
      return isIncludeAttributes();

    case INCLUDE_REFERENCES:
      return isIncludeReferences();

    case INCLUDE_NODE_IDS:
      return isIncludeNodeIDs();

    case INCLUDE_CONTAINED:
      return isIncludeContained();

    case EFFECTIVE_METAMODELS:
      return getEffectiveMetamodels();

    }
    throw new IllegalStateException();
  }

  /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
  public boolean isSet(_Fields field) {
    if (field == null) {
      throw new IllegalArgumentException();
    }

    switch (field) {
    case REPOSITORY_PATTERN:
      return isSetRepositoryPattern();
    case FILE_PATTERNS:
      return isSetFilePatterns();
    case DEFAULT_NAMESPACES:
      return isSetDefaultNamespaces();
    case INCLUDE_ATTRIBUTES:
      return isSetIncludeAttributes();
    case INCLUDE_REFERENCES:
      return isSetIncludeReferences();
    case INCLUDE_NODE_IDS:
      return isSetIncludeNodeIDs();
    case INCLUDE_CONTAINED:
      return isSetIncludeContained();
    case EFFECTIVE_METAMODELS:
      return isSetEffectiveMetamodels();
    }
    throw new IllegalStateException();
  }

  @Override
  public boolean equals(Object that) {
    if (that == null)
      return false;
    if (that instanceof HawkQueryOptions)
      return this.equals((HawkQueryOptions)that);
    return false;
  }

  public boolean equals(HawkQueryOptions that) {
    if (that == null)
      return false;

    boolean this_present_repositoryPattern = true && this.isSetRepositoryPattern();
    boolean that_present_repositoryPattern = true && that.isSetRepositoryPattern();
    if (this_present_repositoryPattern || that_present_repositoryPattern) {
      if (!(this_present_repositoryPattern && that_present_repositoryPattern))
        return false;
      if (!this.repositoryPattern.equals(that.repositoryPattern))
        return false;
    }

    boolean this_present_filePatterns = true && this.isSetFilePatterns();
    boolean that_present_filePatterns = true && that.isSetFilePatterns();
    if (this_present_filePatterns || that_present_filePatterns) {
      if (!(this_present_filePatterns && that_present_filePatterns))
        return false;
      if (!this.filePatterns.equals(that.filePatterns))
        return false;
    }

    boolean this_present_defaultNamespaces = true && this.isSetDefaultNamespaces();
    boolean that_present_defaultNamespaces = true && that.isSetDefaultNamespaces();
    if (this_present_defaultNamespaces || that_present_defaultNamespaces) {
      if (!(this_present_defaultNamespaces && that_present_defaultNamespaces))
        return false;
      if (!this.defaultNamespaces.equals(that.defaultNamespaces))
        return false;
    }

    boolean this_present_includeAttributes = true && this.isSetIncludeAttributes();
    boolean that_present_includeAttributes = true && that.isSetIncludeAttributes();
    if (this_present_includeAttributes || that_present_includeAttributes) {
      if (!(this_present_includeAttributes && that_present_includeAttributes))
        return false;
      if (this.includeAttributes != that.includeAttributes)
        return false;
    }

    boolean this_present_includeReferences = true && this.isSetIncludeReferences();
    boolean that_present_includeReferences = true && that.isSetIncludeReferences();
    if (this_present_includeReferences || that_present_includeReferences) {
      if (!(this_present_includeReferences && that_present_includeReferences))
        return false;
      if (this.includeReferences != that.includeReferences)
        return false;
    }

    boolean this_present_includeNodeIDs = true && this.isSetIncludeNodeIDs();
    boolean that_present_includeNodeIDs = true && that.isSetIncludeNodeIDs();
    if (this_present_includeNodeIDs || that_present_includeNodeIDs) {
      if (!(this_present_includeNodeIDs && that_present_includeNodeIDs))
        return false;
      if (this.includeNodeIDs != that.includeNodeIDs)
        return false;
    }

    boolean this_present_includeContained = true && this.isSetIncludeContained();
    boolean that_present_includeContained = true && that.isSetIncludeContained();
    if (this_present_includeContained || that_present_includeContained) {
      if (!(this_present_includeContained && that_present_includeContained))
        return false;
      if (this.includeContained != that.includeContained)
        return false;
    }

    boolean this_present_effectiveMetamodels = true && this.isSetEffectiveMetamodels();
    boolean that_present_effectiveMetamodels = true && that.isSetEffectiveMetamodels();
    if (this_present_effectiveMetamodels || that_present_effectiveMetamodels) {
      if (!(this_present_effectiveMetamodels && that_present_effectiveMetamodels))
        return false;
      if (!this.effectiveMetamodels.equals(that.effectiveMetamodels))
        return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    List<Object> list = new ArrayList<Object>();

    boolean present_repositoryPattern = true && (isSetRepositoryPattern());
    list.add(present_repositoryPattern);
    if (present_repositoryPattern)
      list.add(repositoryPattern);

    boolean present_filePatterns = true && (isSetFilePatterns());
    list.add(present_filePatterns);
    if (present_filePatterns)
      list.add(filePatterns);

    boolean present_defaultNamespaces = true && (isSetDefaultNamespaces());
    list.add(present_defaultNamespaces);
    if (present_defaultNamespaces)
      list.add(defaultNamespaces);

    boolean present_includeAttributes = true && (isSetIncludeAttributes());
    list.add(present_includeAttributes);
    if (present_includeAttributes)
      list.add(includeAttributes);

    boolean present_includeReferences = true && (isSetIncludeReferences());
    list.add(present_includeReferences);
    if (present_includeReferences)
      list.add(includeReferences);

    boolean present_includeNodeIDs = true && (isSetIncludeNodeIDs());
    list.add(present_includeNodeIDs);
    if (present_includeNodeIDs)
      list.add(includeNodeIDs);

    boolean present_includeContained = true && (isSetIncludeContained());
    list.add(present_includeContained);
    if (present_includeContained)
      list.add(includeContained);

    boolean present_effectiveMetamodels = true && (isSetEffectiveMetamodels());
    list.add(present_effectiveMetamodels);
    if (present_effectiveMetamodels)
      list.add(effectiveMetamodels);

    return list.hashCode();
  }

  @Override
  public int compareTo(HawkQueryOptions other) {
    if (!getClass().equals(other.getClass())) {
      return getClass().getName().compareTo(other.getClass().getName());
    }

    int lastComparison = 0;

    lastComparison = Boolean.valueOf(isSetRepositoryPattern()).compareTo(other.isSetRepositoryPattern());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetRepositoryPattern()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.repositoryPattern, other.repositoryPattern);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetFilePatterns()).compareTo(other.isSetFilePatterns());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetFilePatterns()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.filePatterns, other.filePatterns);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetDefaultNamespaces()).compareTo(other.isSetDefaultNamespaces());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetDefaultNamespaces()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.defaultNamespaces, other.defaultNamespaces);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetIncludeAttributes()).compareTo(other.isSetIncludeAttributes());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetIncludeAttributes()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeAttributes, other.includeAttributes);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetIncludeReferences()).compareTo(other.isSetIncludeReferences());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetIncludeReferences()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeReferences, other.includeReferences);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetIncludeNodeIDs()).compareTo(other.isSetIncludeNodeIDs());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetIncludeNodeIDs()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeNodeIDs, other.includeNodeIDs);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetIncludeContained()).compareTo(other.isSetIncludeContained());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetIncludeContained()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.includeContained, other.includeContained);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    lastComparison = Boolean.valueOf(isSetEffectiveMetamodels()).compareTo(other.isSetEffectiveMetamodels());
    if (lastComparison != 0) {
      return lastComparison;
    }
    if (isSetEffectiveMetamodels()) {
      lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.effectiveMetamodels, other.effectiveMetamodels);
      if (lastComparison != 0) {
        return lastComparison;
      }
    }
    return 0;
  }

  public _Fields fieldForId(int fieldId) {
    return _Fields.findByThriftId(fieldId);
  }

  public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
    schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
  }

  public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
    schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder("HawkQueryOptions(");
    boolean first = true;

    if (isSetRepositoryPattern()) {
      sb.append("repositoryPattern:");
      if (this.repositoryPattern == null) {
        sb.append("null");
      } else {
        sb.append(this.repositoryPattern);
      }
      first = false;
    }
    if (isSetFilePatterns()) {
      if (!first) sb.append(", ");
      sb.append("filePatterns:");
      if (this.filePatterns == null) {
        sb.append("null");
      } else {
        sb.append(this.filePatterns);
      }
      first = false;
    }
    if (isSetDefaultNamespaces()) {
      if (!first) sb.append(", ");
      sb.append("defaultNamespaces:");
      if (this.defaultNamespaces == null) {
        sb.append("null");
      } else {
        sb.append(this.defaultNamespaces);
      }
      first = false;
    }
    if (isSetIncludeAttributes()) {
      if (!first) sb.append(", ");
      sb.append("includeAttributes:");
      sb.append(this.includeAttributes);
      first = false;
    }
    if (isSetIncludeReferences()) {
      if (!first) sb.append(", ");
      sb.append("includeReferences:");
      sb.append(this.includeReferences);
      first = false;
    }
    if (isSetIncludeNodeIDs()) {
      if (!first) sb.append(", ");
      sb.append("includeNodeIDs:");
      sb.append(this.includeNodeIDs);
      first = false;
    }
    if (isSetIncludeContained()) {
      if (!first) sb.append(", ");
      sb.append("includeContained:");
      sb.append(this.includeContained);
      first = false;
    }
    if (isSetEffectiveMetamodels()) {
      if (!first) sb.append(", ");
      sb.append("effectiveMetamodels:");
      if (this.effectiveMetamodels == null) {
        sb.append("null");
      } else {
        sb.append(this.effectiveMetamodels);
      }
      first = false;
    }
    sb.append(")");
    return sb.toString();
  }

  public void validate() throws org.apache.thrift.TException {
    // check for required fields
    // check for sub-struct validity
  }

  private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
    try {
      write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
    } catch (org.apache.thrift.TException te) {
      throw new java.io.IOException(te);
    }
  }

  private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
    try {
      // it doesn't seem like you should have to do this, but java serialization is wacky, and doesn't call the default constructor.
      __isset_bitfield = 0;
      read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
    } catch (org.apache.thrift.TException te) {
      throw new java.io.IOException(te);
    }
  }

  private static class HawkQueryOptionsStandardSchemeFactory implements SchemeFactory {
    public HawkQueryOptionsStandardScheme getScheme() {
      return new HawkQueryOptionsStandardScheme();
    }
  }

  private static class HawkQueryOptionsStandardScheme extends StandardScheme<HawkQueryOptions> {

    public void read(org.apache.thrift.protocol.TProtocol iprot, HawkQueryOptions struct) throws org.apache.thrift.TException {
      org.apache.thrift.protocol.TField schemeField;
      iprot.readStructBegin();
      while (true)
      {
        schemeField = iprot.readFieldBegin();
        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
          break;
        }
        switch (schemeField.id) {
          case 1: // REPOSITORY_PATTERN
            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
              struct.repositoryPattern = iprot.readString();
              struct.setRepositoryPatternIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 2: // FILE_PATTERNS
            if (schemeField.type == org.apache.thrift.protocol.TType.LIST) {
              {
                org.apache.thrift.protocol.TList _list96 = iprot.readListBegin();
                struct.filePatterns = new ArrayList<String>(_list96.size);
                String _elem97;
                for (int _i98 = 0; _i98 < _list96.size; ++_i98)
                {
                  _elem97 = iprot.readString();
                  struct.filePatterns.add(_elem97);
                }
                iprot.readListEnd();
              }
              struct.setFilePatternsIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 3: // DEFAULT_NAMESPACES
            if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
              struct.defaultNamespaces = iprot.readString();
              struct.setDefaultNamespacesIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 4: // INCLUDE_ATTRIBUTES
            if (schemeField.type == org.apache.thrift.protocol.TType.BOOL) {
              struct.includeAttributes = iprot.readBool();
              struct.setIncludeAttributesIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 5: // INCLUDE_REFERENCES
            if (schemeField.type == org.apache.thrift.protocol.TType.BOOL) {
              struct.includeReferences = iprot.readBool();
              struct.setIncludeReferencesIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 6: // INCLUDE_NODE_IDS
            if (schemeField.type == org.apache.thrift.protocol.TType.BOOL) {
              struct.includeNodeIDs = iprot.readBool();
              struct.setIncludeNodeIDsIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 7: // INCLUDE_CONTAINED
            if (schemeField.type == org.apache.thrift.protocol.TType.BOOL) {
              struct.includeContained = iprot.readBool();
              struct.setIncludeContainedIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          case 8: // EFFECTIVE_METAMODELS
            if (schemeField.type == org.apache.thrift.protocol.TType.MAP) {
              {
                org.apache.thrift.protocol.TMap _map99 = iprot.readMapBegin();
                struct.effectiveMetamodels = new HashMap<String,Map<String,List<String>>>(2*_map99.size);
                String _key100;
                Map<String,List<String>> _val101;
                for (int _i102 = 0; _i102 < _map99.size; ++_i102)
                {
                  _key100 = iprot.readString();
                  {
                    org.apache.thrift.protocol.TMap _map103 = iprot.readMapBegin();
                    _val101 = new HashMap<String,List<String>>(2*_map103.size);
                    String _key104;
                    List<String> _val105;
                    for (int _i106 = 0; _i106 < _map103.size; ++_i106)
                    {
                      _key104 = iprot.readString();
                      {
                        org.apache.thrift.protocol.TList _list107 = iprot.readListBegin();
                        _val105 = new ArrayList<String>(_list107.size);
                        String _elem108;
                        for (int _i109 = 0; _i109 < _list107.size; ++_i109)
                        {
                          _elem108 = iprot.readString();
                          _val105.add(_elem108);
                    }
                    iprot.readListEnd();
                  }
                      _val101.put(_key104, _val105);
                    }
                    iprot.readMapEnd();
                  }
                  struct.effectiveMetamodels.put(_key100, _val101);
                }
                iprot.readMapEnd();
              }
              struct.setEffectiveMetamodelsIsSet(true);
            } else { 
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
            }
            break;
          default:
            org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
        }
        iprot.readFieldEnd();
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      struct.validate();
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot, HawkQueryOptions struct) throws org.apache.thrift.TException {
      struct.validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (struct.repositoryPattern != null) {
        if (struct.isSetRepositoryPattern()) {
          oprot.writeFieldBegin(REPOSITORY_PATTERN_FIELD_DESC);
          oprot.writeString(struct.repositoryPattern);
          oprot.writeFieldEnd();
        }
      }
      if (struct.filePatterns != null) {
        if (struct.isSetFilePatterns()) {
          oprot.writeFieldBegin(FILE_PATTERNS_FIELD_DESC);
          {
            oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, struct.filePatterns.size()));
            for (String _iter110 : struct.filePatterns)
            {
              oprot.writeString(_iter110);
            }
            oprot.writeListEnd();
          }
          oprot.writeFieldEnd();
        }
      }
      if (struct.defaultNamespaces != null) {
        if (struct.isSetDefaultNamespaces()) {
          oprot.writeFieldBegin(DEFAULT_NAMESPACES_FIELD_DESC);
          oprot.writeString(struct.defaultNamespaces);
          oprot.writeFieldEnd();
        }
      }
      if (struct.isSetIncludeAttributes()) {
        oprot.writeFieldBegin(INCLUDE_ATTRIBUTES_FIELD_DESC);
        oprot.writeBool(struct.includeAttributes);
        oprot.writeFieldEnd();
      }
      if (struct.isSetIncludeReferences()) {
        oprot.writeFieldBegin(INCLUDE_REFERENCES_FIELD_DESC);
        oprot.writeBool(struct.includeReferences);
        oprot.writeFieldEnd();
      }
      if (struct.isSetIncludeNodeIDs()) {
        oprot.writeFieldBegin(INCLUDE_NODE_IDS_FIELD_DESC);
        oprot.writeBool(struct.includeNodeIDs);
        oprot.writeFieldEnd();
      }
      if (struct.isSetIncludeContained()) {
        oprot.writeFieldBegin(INCLUDE_CONTAINED_FIELD_DESC);
        oprot.writeBool(struct.includeContained);
        oprot.writeFieldEnd();
      }
      if (struct.effectiveMetamodels != null) {
        if (struct.isSetEffectiveMetamodels()) {
          oprot.writeFieldBegin(EFFECTIVE_METAMODELS_FIELD_DESC);
          {
            oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.MAP, struct.effectiveMetamodels.size()));
            for (Map.Entry<String, Map<String,List<String>>> _iter111 : struct.effectiveMetamodels.entrySet())
            {
              oprot.writeString(_iter111.getKey());
            {
                oprot.writeMapBegin(new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.LIST, _iter111.getValue().size()));
                for (Map.Entry<String, List<String>> _iter112 : _iter111.getValue().entrySet())
              {
                  oprot.writeString(_iter112.getKey());
                {
                    oprot.writeListBegin(new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, _iter112.getValue().size()));
                    for (String _iter113 : _iter112.getValue())
                    {
                      oprot.writeString(_iter113);
                }
                oprot.writeListEnd();
              }
            }
            oprot.writeMapEnd();
          }
            }
            oprot.writeMapEnd();
          }
          oprot.writeFieldEnd();
        }
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

  }

  private static class HawkQueryOptionsTupleSchemeFactory implements SchemeFactory {
    public HawkQueryOptionsTupleScheme getScheme() {
      return new HawkQueryOptionsTupleScheme();
    }
  }

  private static class HawkQueryOptionsTupleScheme extends TupleScheme<HawkQueryOptions> {

    @Override
    public void write(org.apache.thrift.protocol.TProtocol prot, HawkQueryOptions struct) throws org.apache.thrift.TException {
      TTupleProtocol oprot = (TTupleProtocol) prot;
      BitSet optionals = new BitSet();
      if (struct.isSetRepositoryPattern()) {
        optionals.set(0);
      }
      if (struct.isSetFilePatterns()) {
        optionals.set(1);
      }
      if (struct.isSetDefaultNamespaces()) {
        optionals.set(2);
      }
      if (struct.isSetIncludeAttributes()) {
        optionals.set(3);
      }
      if (struct.isSetIncludeReferences()) {
        optionals.set(4);
      }
      if (struct.isSetIncludeNodeIDs()) {
        optionals.set(5);
      }
      if (struct.isSetIncludeContained()) {
        optionals.set(6);
      }
      if (struct.isSetEffectiveMetamodels()) {
        optionals.set(7);
      }
      oprot.writeBitSet(optionals, 8);
      if (struct.isSetRepositoryPattern()) {
        oprot.writeString(struct.repositoryPattern);
      }
      if (struct.isSetFilePatterns()) {
        {
          oprot.writeI32(struct.filePatterns.size());
          for (String _iter114 : struct.filePatterns)
          {
            oprot.writeString(_iter114);
          }
        }
      }
      if (struct.isSetDefaultNamespaces()) {
        oprot.writeString(struct.defaultNamespaces);
      }
      if (struct.isSetIncludeAttributes()) {
        oprot.writeBool(struct.includeAttributes);
      }
      if (struct.isSetIncludeReferences()) {
        oprot.writeBool(struct.includeReferences);
      }
      if (struct.isSetIncludeNodeIDs()) {
        oprot.writeBool(struct.includeNodeIDs);
      }
      if (struct.isSetIncludeContained()) {
        oprot.writeBool(struct.includeContained);
      }
      if (struct.isSetEffectiveMetamodels()) {
        {
          oprot.writeI32(struct.effectiveMetamodels.size());
          for (Map.Entry<String, Map<String,List<String>>> _iter115 : struct.effectiveMetamodels.entrySet())
          {
            oprot.writeString(_iter115.getKey());
            {
              oprot.writeI32(_iter115.getValue().size());
              for (Map.Entry<String, List<String>> _iter116 : _iter115.getValue().entrySet())
          {
                oprot.writeString(_iter116.getKey());
            {
                  oprot.writeI32(_iter116.getValue().size());
                  for (String _iter117 : _iter116.getValue())
              {
                    oprot.writeString(_iter117);
                  }
                }
              }
            }
          }
        }
      }
    }

    @Override
    public void read(org.apache.thrift.protocol.TProtocol prot, HawkQueryOptions struct) throws org.apache.thrift.TException {
      TTupleProtocol iprot = (TTupleProtocol) prot;
      BitSet incoming = iprot.readBitSet(8);
      if (incoming.get(0)) {
        struct.repositoryPattern = iprot.readString();
        struct.setRepositoryPatternIsSet(true);
      }
      if (incoming.get(1)) {
        {
          org.apache.thrift.protocol.TList _list118 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
          struct.filePatterns = new ArrayList<String>(_list118.size);
          String _elem119;
          for (int _i120 = 0; _i120 < _list118.size; ++_i120)
          {
            _elem119 = iprot.readString();
            struct.filePatterns.add(_elem119);
          }
        }
        struct.setFilePatternsIsSet(true);
      }
      if (incoming.get(2)) {
        struct.defaultNamespaces = iprot.readString();
        struct.setDefaultNamespacesIsSet(true);
      }
      if (incoming.get(3)) {
        struct.includeAttributes = iprot.readBool();
        struct.setIncludeAttributesIsSet(true);
      }
      if (incoming.get(4)) {
        struct.includeReferences = iprot.readBool();
        struct.setIncludeReferencesIsSet(true);
      }
      if (incoming.get(5)) {
        struct.includeNodeIDs = iprot.readBool();
        struct.setIncludeNodeIDsIsSet(true);
      }
      if (incoming.get(6)) {
        struct.includeContained = iprot.readBool();
        struct.setIncludeContainedIsSet(true);
      }
      if (incoming.get(7)) {
        {
          org.apache.thrift.protocol.TMap _map121 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.MAP, iprot.readI32());
          struct.effectiveMetamodels = new HashMap<String,Map<String,List<String>>>(2*_map121.size);
          String _key122;
          Map<String,List<String>> _val123;
          for (int _i124 = 0; _i124 < _map121.size; ++_i124)
          {
            _key122 = iprot.readString();
          {
              org.apache.thrift.protocol.TMap _map125 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.LIST, iprot.readI32());
              _val123 = new HashMap<String,List<String>>(2*_map125.size);
              String _key126;
              List<String> _val127;
              for (int _i128 = 0; _i128 < _map125.size; ++_i128)
            {
                _key126 = iprot.readString();
              {
                  org.apache.thrift.protocol.TList _list129 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
                  _val127 = new ArrayList<String>(_list129.size);
                  String _elem130;
                  for (int _i131 = 0; _i131 < _list129.size; ++_i131)
                  {
                    _elem130 = iprot.readString();
                    _val127.add(_elem130);
                  }
                }
                _val123.put(_key126, _val127);
              }
            }
            struct.effectiveMetamodels.put(_key122, _val123);
          }
        }
        struct.setEffectiveMetamodelsIsSet(true);
      }
    }
  }

}

